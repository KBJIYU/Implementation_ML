{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 載入基本環境(Basic Environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import requests as rs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import feather as ft\n",
    "import datetime as dt\n",
    "\n",
    "# viz - matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams[u'font.sans-serif'] = ['simhei']\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# viz - others\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import chartify\n",
    "\n",
    "# viz-interact\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# tqdm\n",
    "from tqdm import tqdm \n",
    "\n",
    "# pandas_profiling\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 讀取資料與探索資料(Load Data And EDA)\n",
    "\n",
    "1. **視覺化**\n",
    "    - 查看目標變量的分佈。當分佈不平衡時，根據評分標準和具體模型的使用不同，可能會嚴重影響性能。\n",
    "    - **Numerical Variable**\n",
    "        - 可以用Box Plot來直觀地查看它的分佈。\n",
    "    - X**-Y Label Data**\n",
    "        - 對於坐標類數據，可以用**Scatter Plot**來查看它們的分佈趨勢和是否有離群點的存在。\n",
    "    - **Classification Data**\n",
    "        - 對於分類問題，將數據根據Label 的不同著不同的顏色繪製出來，這對Feature 的構造很有幫助。\n",
    "    - 繪製變量之間兩兩的分佈和相關度圖表。\n",
    "    - [一個在著名的Iris數據集上做了一系列可視化的例子，非常有啟發性。](https://link.zhihu.com/?target=https%3A//www.kaggle.com/benhamner/d/uciml/iris/python-data-visualizations)\n",
    "\n",
    "2. **統計檢定(Statistical Tests)**\n",
    "    - 我們可以對數據進行一些統計上的測試來**驗證一些假設的顯著性**。\n",
    "    - 雖然大部分情況下靠可視化就能得到比較明確的結論，但有一些定量結果總是更理想的。\n",
    "    - 在某些比賽中，由於數據分佈比較奇葩或是噪聲過強，Public LB的分數可能會跟Local CV的結果相去甚遠。可以根據一些統計測試的結果來粗略地建立一個閾值，用來衡量一次分數的提高究竟是實質的提高還是由於數據的隨機性導致的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 識別問題(Identify Problems)\n",
    "1. **識別是分類問題(classification problem)或迴歸問題(regression problem)**\n",
    "    - 當label為二進制(binary values) → 分類問題(classification problem)。\n",
    "        - Single column, binary values (classification problem, one sample belongs to one class only and there are only two classes)\n",
    "        - Multiple column, binary values (classification problem, one sample belongs to one class, but there are more than two classes)\n",
    "    - 當label為實數(real values) → 回歸問題(regression problem)。\n",
    "        - Single column, real values (regression problem, prediction of only one value)\n",
    "        - Multiple column, real values (regression problem, prediction of multiple values)\n",
    "\n",
    "    - 當label不只一種時(multi label) → 分類問題(classification problem)\n",
    "        - And multilabel (classification problem, one sample can belong to several classes)\n",
    "\n",
    "2. **選擇對應的評估指標(Evaluation Metrics)**\n",
    "    - 分類問題(classification problems)\n",
    "        - skewed binary classification problem\n",
    "            - ROC AUC or simply AUC\n",
    "        - multi-label or multi-class classification problems\n",
    "            - categorical cross-entropy\n",
    "            - multiclass log loss\n",
    "    - 回歸問題(regression problems)\n",
    "        - mean squared error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 前處理資料(Data Preprocessing)\n",
    "\n",
    "- 項目\n",
    "    1. 資料合併(merging)。\n",
    "    2. 處理遺失值(missing value)。\n",
    "    3. 處理離群值(outlier)。\n",
    "    4. 處理重複值(duplicates)。\n",
    "    5. 進行資料過篩(filtering)。 \n",
    "    6. 資料儲存(storing)\n",
    "\n",
    "- 參考資料\n",
    "    - [[數據清洗]-Pandas 清洗\"髒\"數據（一）](https://hk.saowen.com/a/b8d38181b1f85660cc25830827acd63bf814aea8f3ea026f7e08fdcdd06c2089)\n",
    "    - [Pythonic Data Cleaning With NumPy and Pandas - Real Python](https://realpython.com/python-data-cleaning-numpy-pandas/)\n",
    "    - [Cleaning Data in Python](https://www.datacamp.com/courses/cleaning-data-in-python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 提取數據特徵(Identification of different variables in the data)\n",
    "\n",
    "1. **確認資料型態**\n",
    "    - 將數據轉化成模型需要的形式。\n",
    "    - 數據有三種類型：\n",
    "        - 數值(numerical variables)\n",
    "        - 類別(categorical variables)\n",
    "        - 文本(variables with text)\n",
    "2. **轉換資料型態(Feature Encoding)**\n",
    "    - 數值資料(numerical variables)\n",
    "        - Separate out the numerical variables first. These variables don’t need any kind of processing and thus we can start applying normalization and machine learning models to these variables.\n",
    "    - 類別資料(categorical variables)\n",
    "        - There are two ways in which we can handle categorical data:\n",
    "            - Convert the categorical data to labels\n",
    "\n",
    "                ```python\n",
    "                from sklearn.preprocessing import LabelEncoder\n",
    "                ```\n",
    "\n",
    "            - Convert the labels to binary variables (one-hot encoding)\n",
    "\n",
    "                ```python\n",
    "                # remember to convert categories to numbers first using LabelEncoder before applying OneHotEncoder on it.\n",
    "                from sklearn.preprocessing import OneHotEncoder\n",
    "                ```\n",
    "\n",
    "        - 假設有一個Categorical Variable 一共有幾萬個取值可能，那麼創建Dummy Variables 的方法就不可行了。\n",
    "        - 這時一個比較好的方法是根據Feature Importance 或是這些取值本身在數據中的出現頻率，為最重要（比如說前95% 的Importance）那些取值（有很大可能只有幾個或是十幾個）創建Dummy Variables，而所有其他取值都歸到一個“其他”類裡面。\n",
    "        - 可參考：\n",
    "\n",
    "            [Guide to Encoding Categorical Values in Python - Practical Business Python](http://pbpython.com/categorical-encoding.html)\n",
    "\n",
    "    - 文本資料(text variables)\n",
    "        - [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)\n",
    "\n",
    "            ```python\n",
    "            from sklearn.feature_extraction.text import CountVectorizer\n",
    "            ```\n",
    "\n",
    "        - [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n",
    "\n",
    "            ```python\n",
    "            from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "            ```\n",
    "\n",
    "            - The TfidfVectorizer performs better than the counts most of the time and I have seen that the following parameters for TfidfVectorizer work almost all the time.\n",
    "\n",
    "                ```python\n",
    "                from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "                tfv = TfidfVectorizer(\n",
    "                \tmin_df=3, max_features=None,\n",
    "                \tstrip_accents='unicode', analyzer='word',\n",
    "                \ttoken_pattern=r'\\w{1,}', ngram_range=(1, 2),\n",
    "                \tuse_idf=1, smooth_idf=1, sublinear_tf=1, \n",
    "                \tstop_words='english;)\n",
    "                ```\n",
    "\n",
    "            - If you are applying these vectorizers only on the training set, make sure to dump it to hard drive so that you can use it later on the validation set.\n",
    "\n",
    "                ```python\n",
    "                import cPickle\n",
    "                cPickle.dump(vectorizer, open('vectorizer.pkl', 'wb'), -1)\n",
    "                ```\n",
    "\n",
    "        - 可參考：\n",
    "\n",
    "            [文本数据预处理：sklearn 中 CountVectorizer、TfidfTransformer 和 TfidfVectorizer - U R MINE - CSDN博客](https://blog.csdn.net/m0_37324740/article/details/79411651)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 切割訓練數據與測試數據(Split the data into two different parts)\n",
    "\n",
    "1. **將原始資料分為訓練資料集(training data)與驗證資料集(validation data)**\n",
    "    - Training Data用於訓練模型。\n",
    "    - Validation Data用於檢驗這個模型的表現。\n",
    "\n",
    "2. **依照問題類型選擇切分方法**\n",
    "    - 分類問題(classification problems)\n",
    "\n",
    "        ```python\n",
    "        from sklearn.model_selection import StratifiedKFold\n",
    "        ```\n",
    "\n",
    "    - 回歸問題(regression problems)\n",
    "\n",
    "        ```python\n",
    "        from sklearn.model_selection import KFold\n",
    "        ```\n",
    "        \n",
    "    - 簡單切\n",
    "      ``` python \n",
    "        from sklearn.cross_validation import train_test_split\n",
    "      ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 架設模型(Modeling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 評估模型(Evaluation Metrics)\n",
    "\n",
    "1. **選擇對應的評估指標(Evaluation Metrics)**\n",
    "    - 分類問題(classification problems)\n",
    "        - skewed binary classification problem\n",
    "            - [參考](https://taweihuang.hpd.io/2018/12/28/imbalanced-data-performance-metrics/)\n",
    "            - ROC AUC or simply AUC\n",
    "        - multi-label or multi-class classification problems\n",
    "            - categorical cross-entropy\n",
    "            - multiclass log loss\n",
    "    - 回歸問題(regression problems)\n",
    "        - mean squared error\n",
    "\n",
    "2. **常用分類問題指標**\n",
    "    | 混淆矩陣         | 「模型預測」為真 (positive) | 「模型預測」為非 (negative) | Rows Totals | \n",
    "    |------------------|-----------------------------|-----------------------------| --- |\n",
    "    | 「真實情況」為真 | true positive (TP)          | false negative (FN)         |  P  |\n",
    "    | 「真實情況」為非 | false positive (FP)         | true negative (TN)          | N  |\n",
    "\n",
    "    - 混淆矩陣相關(Confusion Matrix)\n",
    "      - [可參考](https://ithelp.ithome.com.tw/articles/10222697)\n",
    "      - Accuracy: \n",
    "        - `Accuracy=[(TP)+(TN)]/(TP+TN+FP+FN)`\n",
    "        - 最經典的顯示模型的正確度\n",
    "      - Precision: \n",
    "        - `Precision=(TP)/(TP+FP)`\n",
    "        - 我們比較重視「模型預測為真」的結果，是否能符合現實。真實為非(FN)」的影響相對比較還好。\n",
    "      - Recall: \n",
    "        - `Recall=(TP)/(TP+FN)`\n",
    "        - 我們比較重視「真實為真」的結果，模型能不能預測到。\n",
    "      - F-Measure:\n",
    "        - `F1 = 2*[(Precision*Recall)/(Precision+Recall)] = 2/(1/precision+1/recall)`\n",
    "        - 自動化權衡Precision和Recall。\n",
    "      - ROC曲線(Receiver Operating Characteristic)\n",
    "        - [wiki介紹得很清楚](https://zh.wikipedia.org/wiki/ROC%E6%9B%B2%E7%BA%BF)\n",
    "        - 縱軸 TPR(True Positive Rate): \n",
    "          - `TPR=(TP)/P=(TP)/(TP+FN)`\n",
    "          - 真實為P且預測為P的比率\n",
    "        - 橫軸 FPR(False Positive Rate): \n",
    "          - `FPR=(TP)/N=(TP)/(FP+TN)`\n",
    "          - 真實為N但預測為P的比率\n",
    "      - AUC(Area Under Curve)\n",
    "        - [wiki介紹得很清楚](https://zh.wikipedia.org/wiki/ROC%E6%9B%B2%E7%BA%BF)\n",
    "        - 簡單說：AUC值越大的分類器，正確率越高。\n",
    "        - 從AUC判斷分類器（預測模型）優劣的標準：\n",
    "          - AUC = 1，是完美分類器，採用這個預測模型時，存在至少一個閾值能得出完美預測。絕大多數預測的場合，不存在完美分類器。\n",
    "          - 0.5 < AUC < 1，優於隨機猜測。這個分類器（模型）妥善設定閾值的話，能有預測價值。\n",
    "          - AUC = 0.5，跟隨機猜測一樣（例：丟銅板），模型沒有預測價值。\n",
    "          - AUC < 0.5，比隨機猜測還差；但只要總是反預測而行，就優於隨機猜測。\n",
    "        - AUC of ROC是機器學習的社群最常使用來比較不同模型優劣的方法。然而近來這個做法開始受到質疑，因為有些機器學習的研究指出，AUC的雜訊太多，並且很常求不出可信又有效的AUC值（此時便不能保證AUC傳達本節開頭所述之意義），使得AUC在模型比較時產生的問題比解釋的問題更多\n",
    "    - 交叉熵(cross-entropy)\n",
    "      - [參考](https://medium.com/@chih.sheng.huang821/%E6%A9%9F%E5%99%A8-%E6%B7%B1%E5%BA%A6%E5%AD%B8%E7%BF%92-%E5%9F%BA%E7%A4%8E%E4%BB%8B%E7%B4%B9-%E6%90%8D%E5%A4%B1%E5%87%BD%E6%95%B8-loss-function-2dcac5ebb6cb)\n",
    "- 損失函數(loss function)\n",
    "  - MSE\n",
    "\n",
    "\n",
    "- 梯度下降(gradient descent)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "360px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
